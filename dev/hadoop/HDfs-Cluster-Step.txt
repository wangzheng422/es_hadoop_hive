docker run --net host --name hdfs-name -e SERVER_ROLE=nn -e FIRST_TIME=true -v/data:/data  hdfs
docker run --net host --name hdfs-data -e SERVER_ROLE=dn -eNAME_NODE_IP=hdfs://{{NameNode IP}}:9000 -v/data:/data hdfs



# SETUP WITH DATA
export NAMENODE=10.171.129.10
export DATANODES=10.171.128.37
export SSH_PORT=2222

export IMAGETAG=v20161105.125343
docker pull index.alauda.cn/danielalauda/hadooptest:$IMAGETAG

# TO RUN A YARN CLUSTER
# master
# replace node ips with each node ip
docker run -d \
  --log-driver=json-file \
  --net host \
  -e SSH_PORT=$SSH_PORT \
  -e NODE_IPS=$DATANODES \
  -e NAME_NODE_PORT=9000 \
  -e NAME_NODE_ADDR=$NAMENODE \
  -e SERVER_ROLE=nn \
  -e FIRST_TIME=true \
  -e START_YARN=true \
  -e TEST=true \
  -e DEBUG=true \
  --name hadoop-namenode \
  index.alauda.cn/danielalauda/hadooptest:$IMAGETAG && docker logs -f hadoop-namenode


# NODE ONLY
# each node
docker run -d \
  --log-driver=json-file \
  --net host \
  -e SSH_PORT=$SSH_PORT \
  -e NODE_IPS=$DATANODES \
  -e NAME_NODE_ADDR=$NAMENODE \
  -e NAME_NODE_PORT=9000 \
  -e SERVER_ROLE=dn \
  -e FIRST_TIME=true \
  -e START_YARN=true \
  -e TEST=true \
  -e DEBUG=true \
  --name hadoop-datanode \
  index.alauda.cn/danielalauda/hadooptest:$IMAGETAG && docker logs -f hadoop-datanode
